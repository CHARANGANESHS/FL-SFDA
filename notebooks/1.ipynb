{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_datasets():\n",
    "    transform = transforms.ToTensor()\n",
    "\n",
    "    full_train = torchvision.datasets.MNIST(\n",
    "        root=\"../data\", train=True, download=True, transform=transform\n",
    "    )\n",
    "    full_test = torchvision.datasets.MNIST(\n",
    "        root=\"../data\", train=False, download=True, transform=transform\n",
    "    )\n",
    "\n",
    "    # Collect indices per class\n",
    "    class_indices = [[] for _ in range(10)]\n",
    "    for idx, (img, label) in enumerate(full_train):\n",
    "        class_indices[label].append(idx)\n",
    "\n",
    "    # Build subsets per digit class\n",
    "    class_datasets = []\n",
    "    for digit in range(10):\n",
    "        subset_indices = class_indices[digit]\n",
    "        class_subset = torch.utils.data.Subset(full_train, subset_indices)\n",
    "        class_datasets.append(class_subset)\n",
    "\n",
    "    return class_datasets, full_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_domain_adaptation(\n",
    "    source_img: torch.Tensor,\n",
    "    alpha: float = 0.1\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Simple demonstration for FDA: we add a bit of random phase noise in the Fourier domain.\n",
    "    source_img: (1, 28, 28)  # for MNIST, single channel\n",
    "    alpha: how strong the style perturbation should be\n",
    "    \"\"\"\n",
    "    # Convert to frequency domain\n",
    "    fft_source = torch.fft.fft2(source_img)\n",
    "    fft_source_shifted = torch.fft.fftshift(fft_source)\n",
    "\n",
    "    # Create random phase noise\n",
    "    _, h, w = source_img.shape\n",
    "    noise = torch.exp(1j * 2 * np.pi * torch.rand((h, w)))\n",
    "\n",
    "    # Blend with alpha\n",
    "    # We'll blend the magnitude of source with random phase\n",
    "    magnitude = torch.abs(fft_source_shifted)\n",
    "    phase = torch.angle(fft_source_shifted)\n",
    "    random_phase = torch.angle(noise)\n",
    "\n",
    "    new_phase = (1 - alpha) * phase + alpha * random_phase\n",
    "    new_fft = magnitude * torch.exp(1j * new_phase)\n",
    "\n",
    "    # Inverse shift and inverse FFT\n",
    "    new_fft_ishifted = torch.fft.ifftshift(new_fft)\n",
    "    perturbed_img = torch.fft.ifft2(new_fft_ishifted).real\n",
    "\n",
    "    return perturbed_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDADataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps a Subset of MNIST, applying Fourier Domain Adaptation (FDA) to each sample.\n",
    "    \"\"\"\n",
    "    def __init__(self, subset, alpha=0.1):\n",
    "        self.subset = subset\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, label = self.subset[idx]\n",
    "        # img shape: [1, 28, 28] (already a tensor from transforms.ToTensor())\n",
    "        # Apply FDA\n",
    "        perturbed_img = fourier_domain_adaptation(img, alpha=self.alpha)\n",
    "        return perturbed_img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientNode:\n",
    "    \"\"\"\n",
    "    Represents a federated client responsible for training on its local dataset\n",
    "    (which in this case is one digit class + some FDA-based perturbation).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, client_id, dataset, batch_size=64, lr=0.01, device='cpu'):\n",
    "        self.client_id = client_id\n",
    "        self.dataset = dataset\n",
    "        self.device = device\n",
    "\n",
    "        self.dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        self.lr = lr\n",
    "\n",
    "    def local_train(self, global_model: nn.Module, epochs=1):\n",
    "        \"\"\"\n",
    "        Train a copy of the global model on the local dataset for a few epochs,\n",
    "        and return the updated state_dict.\n",
    "        \"\"\"\n",
    "        model = SimpleCNN().to(self.device)\n",
    "        model.load_state_dict(global_model.state_dict())  # copy global weights\n",
    "\n",
    "        optimizer = optim.SGD(model.parameters(), lr=self.lr)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            for images, labels in self.dataloader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        return model.state_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedServer:\n",
    "    \"\"\"\n",
    "    Central server orchestrating federated training:\n",
    "    - Initializes a global model\n",
    "    - Sends it to each client\n",
    "    - Averages updates\n",
    "    - Repeats for multiple rounds\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=10, device='cpu'):\n",
    "        self.global_model = SimpleCNN(num_classes).to(device)\n",
    "        self.device = device\n",
    "\n",
    "    def aggregate_weights(self, client_state_dicts):\n",
    "        \"\"\"\n",
    "        Perform a simple FedAvg (weighted average if needed, or just an average).\n",
    "        \"\"\"\n",
    "        # Create a new state dict as the average\n",
    "        global_state_dict = {}\n",
    "        # Initialize with zeros\n",
    "        for key in client_state_dicts[0].keys():\n",
    "            global_state_dict[key] = torch.zeros_like(client_state_dicts[0][key])\n",
    "\n",
    "        # Sum up all client weights\n",
    "        for state_dict in client_state_dicts:\n",
    "            for key in state_dict.keys():\n",
    "                global_state_dict[key] += state_dict[key]\n",
    "\n",
    "        # Average\n",
    "        for key in global_state_dict.keys():\n",
    "            global_state_dict[key] = global_state_dict[key] / len(client_state_dicts)\n",
    "\n",
    "        return global_state_dict\n",
    "\n",
    "    def update_global_model(self, global_state_dict):\n",
    "        self.global_model.load_state_dict(global_state_dict)\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        \"\"\"\n",
    "        Evaluate the global model on a test set.\n",
    "        \"\"\"\n",
    "        self.global_model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(self.device), labels.to(self.device)\n",
    "                outputs = self.global_model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        return 100.0 * correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_federated_sdfa_mnist(\n",
    "    rounds=5, local_epochs=1, alpha=0.1, batch_size=64, lr=0.01, device='cpu'\n",
    "):\n",
    "    # 1. Load the data\n",
    "    class_datasets, full_test = load_mnist_datasets()\n",
    "\n",
    "    # 2. Create FDADatasets for each digit class\n",
    "    #    (each \"client\" sees images of a single digit, plus FDA perturbation)\n",
    "    fda_clients = []\n",
    "    for i, subset in enumerate(class_datasets):\n",
    "        client_dataset = FDADataset(subset, alpha=alpha)\n",
    "        fda_clients.append(\n",
    "            ClientNode(client_id=i, dataset=client_dataset, batch_size=batch_size, lr=lr, device=device)\n",
    "        )\n",
    "\n",
    "    # 3. Global server\n",
    "    server = FedServer(num_classes=10, device=device)\n",
    "\n",
    "    # 4. Test loader\n",
    "    test_loader = DataLoader(full_test, batch_size=256, shuffle=False)\n",
    "\n",
    "    # 5. Federated Rounds\n",
    "    for r in range(rounds):\n",
    "        client_weights = []\n",
    "        # Each client trains locally\n",
    "        for client in fda_clients:\n",
    "            local_state_dict = client.local_train(global_model=server.global_model, epochs=local_epochs)\n",
    "            client_weights.append(local_state_dict)\n",
    "\n",
    "        # Server aggregates\n",
    "        aggregated = server.aggregate_weights(client_weights)\n",
    "        server.update_global_model(aggregated)\n",
    "\n",
    "        # Evaluate after this round\n",
    "        acc = server.evaluate(test_loader)\n",
    "        print(f\"[Round {r+1}] Global Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "    print(\"Federated training with SFDA on MNIST is complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Round 1] Global Test Accuracy: 9.95%\n",
      "[Round 2] Global Test Accuracy: 14.30%\n",
      "[Round 3] Global Test Accuracy: 14.93%\n",
      "[Round 4] Global Test Accuracy: 18.73%\n",
      "[Round 5] Global Test Accuracy: 25.91%\n",
      "[Round 6] Global Test Accuracy: 32.79%\n",
      "[Round 7] Global Test Accuracy: 35.90%\n",
      "[Round 8] Global Test Accuracy: 40.51%\n",
      "[Round 9] Global Test Accuracy: 45.53%\n",
      "[Round 10] Global Test Accuracy: 48.60%\n",
      "Federated training with SFDA on MNIST is complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    main_federated_sdfa_mnist(\n",
    "        rounds=10,        # Number of federated rounds\n",
    "        local_epochs=1,  # Local epochs per round\n",
    "        alpha=0.1,       # Strength of FDA perturbation\n",
    "        batch_size=64,\n",
    "        lr=0.01,\n",
    "        device=device\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
